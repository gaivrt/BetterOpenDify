import json
import logging
from flask import Flask, request, Response, stream_with_context
import httpx
import time
from dotenv import load_dotenv
import os
import ast
from threading import Lock
from typing import Dict, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è®¾ç½® httpx çš„æ—¥å¿—çº§åˆ«
logging.getLogger("httpx").setLevel(logging.DEBUG)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class ConversationMapper:
    """ç®¡ç† Open WebUI chat_id åˆ° Dify conversation_id çš„æ˜ å°„å…³ç³»"""
    
    def __init__(self, storage_file="data/conversation_mappings.json"):
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(storage_file), exist_ok=True)
        self.storage_file = storage_file
        self._mapping: Dict[str, dict] = {}  # æ”¹ä¸ºdictå­˜å‚¨æ›´å¤šä¿¡æ¯
        self._lock = Lock()
        self._load_mappings()
        logger.info("âœ… ConversationMapper initialized")
    
    def _load_mappings(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½æ˜ å°„å…³ç³»"""
        try:
            if os.path.exists(self.storage_file):
                with open(self.storage_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self._mapping = data
                    logger.info(f"ğŸ“‚ Loaded {len(self._mapping)} conversation mappings from {self.storage_file}")
            else:
                logger.info(f"ğŸ“‚ No existing mappings file found, starting fresh")
        except Exception as e:
            logger.error(f"âŒ Failed to load mappings from {self.storage_file}: {e}")
            self._mapping = {}
    
    def _save_mappings(self) -> None:
        """ä¿å­˜æ˜ å°„å…³ç³»åˆ°æ–‡ä»¶"""
        try:
            with open(self.storage_file, 'w', encoding='utf-8') as f:
                json.dump(self._mapping, f, ensure_ascii=False, indent=2)
            logger.debug(f"ğŸ’¾ Saved {len(self._mapping)} mappings to {self.storage_file}")
        except Exception as e:
            logger.error(f"âŒ Failed to save mappings to {self.storage_file}: {e}")
    
    def get_dify_conversation_id(self, webui_chat_id: str) -> Optional[str]:
        """æ ¹æ® Open WebUI chat_id è·å–å¯¹åº”çš„ Dify conversation_id"""
        with self._lock:
            mapping_info = self._mapping.get(webui_chat_id)
            return mapping_info.get('dify_conversation_id') if mapping_info else None
    
    def set_mapping(self, webui_chat_id: str, dify_conversation_id: str) -> None:
        """è®¾ç½®æ˜ å°„å…³ç³»"""
        with self._lock:
            self._mapping[webui_chat_id] = {
                'dify_conversation_id': dify_conversation_id,
                'created_at': int(time.time()),
                'last_used': int(time.time())
            }
            self._save_mappings()  # ç«‹å³æŒä¹…åŒ–
            logger.info(f"ğŸ”— Mapped WebUI chat_id {webui_chat_id[:8]}... to Dify conversation_id {dify_conversation_id[:8]}...")
    
    def has_mapping(self, webui_chat_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ˜ å°„å…³ç³»"""
        with self._lock:
            return webui_chat_id in self._mapping
    
    def remove_mapping(self, webui_chat_id: str) -> bool:
        """åˆ é™¤æ˜ å°„å…³ç³»"""
        with self._lock:
            if webui_chat_id in self._mapping:
                del self._mapping[webui_chat_id]
                self._save_mappings()  # ç«‹å³æŒä¹…åŒ–
                logger.info(f"ğŸ—‘ï¸  Removed mapping for WebUI chat_id {webui_chat_id[:8]}...")
                return True
            return False
    
    def get_mapping_count(self) -> int:
        """è·å–å½“å‰æ˜ å°„æ•°é‡"""
        with self._lock:
            return len(self._mapping)
    
    def update_last_used(self, webui_chat_id: str) -> None:
        """æ›´æ–°æ˜ å°„çš„æœ€åä½¿ç”¨æ—¶é—´"""
        with self._lock:
            if webui_chat_id in self._mapping:
                self._mapping[webui_chat_id]['last_used'] = int(time.time())
                self._save_mappings()
    
    def cleanup_old_mappings(self, max_age_days: int = 30) -> int:
        """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ˜ å°„"""
        cutoff_time = int(time.time()) - (max_age_days * 24 * 60 * 60)
        removed_count = 0
        
        with self._lock:
            keys_to_remove = []
            for chat_id, mapping_info in self._mapping.items():
                if mapping_info.get('last_used', 0) < cutoff_time:
                    keys_to_remove.append(chat_id)
            
            for key in keys_to_remove:
                del self._mapping[key]
                removed_count += 1
            
            if removed_count > 0:
                self._save_mappings()
                logger.info(f"ğŸ§¹ Cleaned up {removed_count} old mappings (older than {max_age_days} days)")
        
        return removed_count
    
    def get_mapping_stats(self) -> dict:
        """è·å–æ˜ å°„ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            if not self._mapping:
                return {"total": 0, "oldest": None, "newest": None}
            
            created_times = [info.get('created_at', 0) for info in self._mapping.values()]
            return {
                "total": len(self._mapping),
                "oldest": min(created_times) if created_times else None,
                "newest": max(created_times) if created_times else None
            }

# å…¨å±€ä¼šè¯æ˜ å°„å™¨å®ä¾‹
conversation_mapper = ConversationMapper()

def parse_model_config():
    """
    ä»ç¯å¢ƒå˜é‡è§£ææ¨¡å‹é…ç½®
    è¿”å›ä¸€ä¸ªå­—å…¸ {model_name: api_key}
    """
    try:
        config_str = os.getenv('MODEL_CONFIG', '{}')
        if not config_str.strip():
            logger.warning("MODEL_CONFIG is empty, no models will be available")
            return {}
            
        # å°è¯•ä½œä¸ºPythonå­—å…¸è§£æ
        try:
            result = ast.literal_eval(config_str)
            if not isinstance(result, dict):
                logger.error("MODEL_CONFIG must be a dictionary")
                return {}
            return result
        except (SyntaxError, ValueError) as e:
            logger.error(f"Failed to parse MODEL_CONFIG as Python dict: {e}")
            try:
                # å°è¯•ä½œä¸ºJSONè§£æ
                result = json.loads(config_str)
                if not isinstance(result, dict):
                    logger.error("MODEL_CONFIG must be a dictionary")
                    return {}
                return result
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse MODEL_CONFIG as JSON: {e}")
                return {}
    except Exception as e:
        logger.error(f"Error parsing MODEL_CONFIG: {e}")
        return {}

def validate_startup_config():
    """éªŒè¯å¯åŠ¨é…ç½®"""
    issues = []
    
    # æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
    dify_api_base = os.getenv("DIFY_API_BASE", "")
    if not dify_api_base.strip():
        issues.append("DIFY_API_BASE is not set or empty")
    elif not (dify_api_base.startswith("http://") or dify_api_base.startswith("https://")):
        issues.append(f"DIFY_API_BASE must be a valid URL, got: {dify_api_base}")
    
    # æ£€æŸ¥æ¨¡å‹é…ç½®
    if not MODEL_TO_API_KEY:
        issues.append("No valid models configured in MODEL_CONFIG")
    else:
        for model_name, api_key in MODEL_TO_API_KEY.items():
            if not api_key or not api_key.strip():
                issues.append(f"Empty API key for model: {model_name}")
            elif not isinstance(api_key, str):
                issues.append(f"API key must be string for model: {model_name}")
    
    # æŠ¥å‘Šé—®é¢˜
    if issues:
        logger.error("Configuration validation failed:")
        for issue in issues:
            logger.error(f"  - {issue}")
        logger.error("Please check your .env file and fix these issues")
        return False
    
    logger.info("âœ… Configuration validation passed")
    logger.info(f"âœ… Loaded {len(MODEL_TO_API_KEY)} model(s): {', '.join(MODEL_TO_API_KEY.keys())}")
    logger.info(f"âœ… Dify API base: {dify_api_base}")
    return True

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
MODEL_TO_API_KEY = parse_model_config()

# æ ¹æ®MODEL_TO_API_KEYè‡ªåŠ¨ç”Ÿæˆæ¨¡å‹ä¿¡æ¯
AVAILABLE_MODELS = [
    {
        "id": model_id,
        "object": "model",
        "created": int(time.time()),
        "owned_by": "dify"
    }
    for model_id, api_key in MODEL_TO_API_KEY.items()
    if api_key is not None  # åªåŒ…å«é…ç½®äº†API Keyçš„æ¨¡å‹
]

app = Flask(__name__)

# ä»ç¯å¢ƒå˜é‡è·å–APIåŸºç¡€URL
DIFY_API_BASE = os.getenv("DIFY_API_BASE", "https://mify-be.pt.xiaomi.com/api/v1")

# å…¨å±€HTTPå®¢æˆ·ç«¯é…ç½®
HTTP_CLIENT_CONFIG = {
    "timeout": 30.0,
    "limits": httpx.Limits(max_keepalive_connections=20, max_connections=100),
    "follow_redirects": True
}

# å…¨å±€HTTPå®¢æˆ·ç«¯å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_http_client = None

def get_http_client():
    """è·å–æˆ–åˆ›å»ºå…¨å±€HTTPå®¢æˆ·ç«¯"""
    global _http_client
    if _http_client is None:
        _http_client = httpx.Client(**HTTP_CLIENT_CONFIG)
        logger.info("âœ… HTTP client initialized with connection pooling")
    return _http_client

def cleanup_http_client():
    """æ¸…ç†HTTPå®¢æˆ·ç«¯èµ„æº"""
    global _http_client
    if _http_client is not None:
        _http_client.close()
        _http_client = None
        logger.info("âœ… HTTP client resources cleaned up")

def get_api_key(model_name):
    """æ ¹æ®æ¨¡å‹åç§°è·å–å¯¹åº”çš„APIå¯†é’¥"""
    api_key = MODEL_TO_API_KEY.get(model_name)
    if not api_key:
        logger.warning(f"No API key found for model: {model_name}")
    return api_key

def extract_webui_chat_id() -> Optional[str]:
    """ä»è¯·æ±‚ä¸­æå– Open WebUI çš„ chat_id"""
    # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰è¯·æ±‚å¤´
    logger.debug(f"ğŸ” All headers: {dict(request.headers)}")
    
    # è°ƒè¯•ï¼šé€ä¸ªæ‰“å°æ¯ä¸ªå¤´éƒ¨çš„åç§°å’Œå€¼
    logger.debug("ğŸ” Raw headers inspection:")
    for header_name, header_value in request.headers:
        logger.debug(f"ğŸ”   '{header_name}' = '{header_value}'")
        # æ£€æŸ¥æ˜¯å¦åŒ…å«chat-idç›¸å…³å­—ç¬¦ä¸²
        if 'chat' in header_name.lower():
            logger.debug(f"ğŸ”   ^^^ This header contains 'chat'!")
    
    # æ–¹æ³•1: ä» HTTP Header æå– (æ”¯æŒå¤šç§å¤§å°å†™å½¢å¼)
    possible_headers = ['X-OpenWebUI-Chat-Id', 'x-openwebui-chat-id', 'X-Openwebui-Chat-Id']
    chat_id = None
    
    for header_name in possible_headers:
        chat_id = request.headers.get(header_name)
        if chat_id:
            logger.debug(f"ğŸ” Found chat_id in header '{header_name}': {chat_id[:8]}...")
            return chat_id
    
    # æ–¹æ³•1.5: ç›´æ¥éå†æ‰€æœ‰å¤´éƒ¨æŸ¥æ‰¾åŒ…å« chat-id çš„
    for header_name, header_value in request.headers:
        if 'chat-id' in header_name.lower():
            logger.debug(f"ğŸ” Found chat_id in header '{header_name}': {header_value[:8]}...")
            return header_value
    
    # æ–¹æ³•2: ä»è¯·æ±‚ä½“çš„ metadata æå–
    try:
        request_json = request.get_json() or {}
        metadata = request_json.get('metadata', {})
        chat_id = metadata.get('chat_id')
        if chat_id:
            logger.debug(f"ğŸ” Found chat_id in metadata: {chat_id[:8]}...")
            return chat_id
    except Exception as e:
        logger.debug(f"Failed to extract chat_id from metadata: {e}")
    
    # æ–¹æ³•3: æ£€æŸ¥User-Agentï¼Œå¦‚æœæ˜¯OpenWebUIçš„åç«¯ï¼Œå¯èƒ½éœ€è¦å…¶ä»–æ–¹å¼è·å–chat_id
    user_agent = request.headers.get('User-Agent', '')
    if 'aiohttp' in user_agent:
        logger.debug("ğŸ” Request from aiohttp (likely Open WebUI backend) but no chat_id header found")
        # å¯ä»¥æ·»åŠ æ›´å¤šæå–é€»è¾‘ï¼Œæ¯”å¦‚ä»Authorization headeræˆ–å…¶ä»–åœ°æ–¹
    
    logger.debug("ğŸ” No chat_id found in request")
    return None

def extract_webui_user_id() -> Optional[str]:
    """ä»è¯·æ±‚ä¸­æå– Open WebUI çš„ user_id"""
    # è°ƒè¯•ï¼šæŸ¥æ‰¾ç”¨æˆ·IDç›¸å…³å¤´éƒ¨
    logger.debug("ğŸ” Searching for user_id in headers:")
    for header_name, header_value in request.headers:
        if 'user' in header_name.lower():
            logger.debug(f"ğŸ”   Found user-related header: '{header_name}' = '{header_value[:8]}...'")
    
    # æ–¹æ³•1: ä» HTTP Header æå– (æ”¯æŒå¤šç§å¤§å°å†™å½¢å¼)
    possible_headers = ['X-OpenWebUI-User-Id', 'x-openwebui-user-id', 'X-Openwebui-User-Id']
    
    for header_name in possible_headers:
        user_id = request.headers.get(header_name)
        if user_id:
            logger.debug(f"ğŸ” Found user_id in header '{header_name}': {user_id[:8]}...")
            return user_id
    
    # æ–¹æ³•2: ç›´æ¥éå†æ‰€æœ‰å¤´éƒ¨æŸ¥æ‰¾åŒ…å« user-id çš„
    for header_name, header_value in request.headers:
        if 'user-id' in header_name.lower():
            logger.debug(f"ğŸ” Found user_id in header '{header_name}': {header_value[:8]}...")
            return header_value
    
    # æ–¹æ³•3: ä»è¯·æ±‚ä½“çš„ metadata æå–
    try:
        request_json = request.get_json() or {}
        metadata = request_json.get('metadata', {})
        user_id = metadata.get('user_id')
        if user_id:
            logger.debug(f"ğŸ” Found user_id in metadata: {user_id[:8]}...")
            return user_id
    except Exception as e:
        logger.debug(f"Failed to extract user_id from metadata: {e}")
    
    logger.debug("ğŸ” No user_id found in request")
    return None

def transform_openai_to_dify(openai_request, endpoint, webui_chat_id=None):
    """å°†OpenAIæ ¼å¼çš„è¯·æ±‚è½¬æ¢ä¸ºDifyæ ¼å¼"""
    
    if endpoint == "/chat/completions":
        messages = openai_request.get("messages", [])
        stream = openai_request.get("stream", False)
        
        # å¤„ç† conversation_id æ˜ å°„
        dify_conversation_id = None
        if webui_chat_id:
            dify_conversation_id = conversation_mapper.get_dify_conversation_id(webui_chat_id)
            if dify_conversation_id:
                conversation_mapper.update_last_used(webui_chat_id)  # æ›´æ–°ä½¿ç”¨æ—¶é—´
            logger.info(f"ğŸ”„ WebUI chat_id: {webui_chat_id[:8]}... -> Dify conversation_id: {dify_conversation_id[:8] if dify_conversation_id else 'None'}...")
        
        # æå–ç”¨æˆ·ID - ä¼˜å…ˆçº§é¡ºåº
        user_id = (
            openai_request.get("user") or      # 1. OpenAIè¯·æ±‚ä½“ä¸­çš„userå­—æ®µ
            extract_webui_user_id() or         # 2. OpenWebUIå¤´éƒ¨ä¸­çš„user-id  
            "default_user"                     # 3. é»˜è®¤å€¼
        )
        
        logger.debug(f"ğŸ‘¤ User ID resolved: {user_id[:8] if user_id != 'default_user' else user_id}...")
        
        dify_request = {
            "inputs": {},
            "query": messages[-1]["content"] if messages else "",
            "response_mode": "streaming" if stream else "blocking",
            "conversation_id": dify_conversation_id,
            "user": user_id
        }

        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆåªåœ¨æ²¡æœ‰ conversation_id æ—¶ä½¿ç”¨ï¼Œé¿å…é‡å¤ï¼‰
        if not dify_conversation_id and len(messages) > 1:
            history = []
            for msg in messages[:-1]:  # é™¤äº†æœ€åä¸€æ¡æ¶ˆæ¯
                history.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
            dify_request["conversation_history"] = history
            logger.debug(f"ğŸ“ Added {len(history)} history messages (no conversation_id)")

        return dify_request
    
    return None

def transform_dify_to_openai(dify_response, model="claude-3-5-sonnet-v2", stream=False):
    """å°†Difyæ ¼å¼çš„å“åº”è½¬æ¢ä¸ºOpenAIæ ¼å¼"""
    
    if not stream:
        return {
            "id": dify_response.get("message_id", ""),
            "object": "chat.completion",
            "created": dify_response.get("created", int(time.time())),
            "model": model,  # ä½¿ç”¨å®é™…ä½¿ç”¨çš„æ¨¡å‹
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": dify_response.get("answer", "")
                },
                "finish_reason": "stop"
            }]
        }
    else:
        # æµå¼å“åº”çš„è½¬æ¢åœ¨stream_responseå‡½æ•°ä¸­å¤„ç†
        return dify_response

def create_openai_stream_response(content, message_id, model="claude-3-5-sonnet-v2"):
    """åˆ›å»ºOpenAIæ ¼å¼çš„æµå¼å“åº”"""
    return {
        "id": message_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [{
            "index": 0,
            "delta": {
                "content": content
            },
            "finish_reason": None
        }]
    }

def update_conversation_mapping(webui_chat_id: str, dify_response: dict) -> None:
    """ä» Dify å“åº”ä¸­æå– conversation_id å¹¶æ›´æ–°æ˜ å°„"""
    if not webui_chat_id:
        return
    
    # æå– conversation_id
    dify_conversation_id = dify_response.get("conversation_id")
    if dify_conversation_id and not conversation_mapper.has_mapping(webui_chat_id):
        conversation_mapper.set_mapping(webui_chat_id, dify_conversation_id)
        logger.info(f"ğŸ†• New conversation mapping established")
    elif dify_conversation_id:
        logger.debug(f"âœ… Conversation mapping already exists")

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    try:
        openai_request = request.get_json()
        logger.info(f"Received request: {json.dumps(openai_request, ensure_ascii=False)}")
        
        # æå– Open WebUI chat_id å’Œ user_id
        webui_chat_id = extract_webui_chat_id()
        webui_user_id = extract_webui_user_id()
        
        if webui_chat_id:
            logger.info(f"ğŸ”— Processing request for WebUI chat_id: {webui_chat_id[:8]}...")
        if webui_user_id:
            logger.info(f"ğŸ‘¤ Processing request for WebUI user_id: {webui_user_id[:8]}...")
        
        model = openai_request.get("model", "claude-3-5-sonnet-v2")
        logger.info(f"Using model: {model}")
        
        # éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ
        api_key = get_api_key(model)
        if not api_key:
            error_msg = f"Model {model} is not supported. Available models: {', '.join(MODEL_TO_API_KEY.keys())}"
            logger.error(error_msg)
            return {
                "error": {
                    "message": error_msg,
                    "type": "invalid_request_error",
                    "code": "model_not_found"
                }
            }, 404
            
        dify_request = transform_openai_to_dify(openai_request, "/chat/completions", webui_chat_id)
        logger.info(f"Transformed request: {json.dumps(dify_request, ensure_ascii=False)}")
        
        if not dify_request:
            logger.error("Failed to transform request")
            return {
                "error": {
                    "message": "Invalid request format",
                    "type": "invalid_request_error",
                }
            }, 400

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        stream = openai_request.get("stream", False)
        dify_endpoint = f"{DIFY_API_BASE}/chat-messages"
        logger.info(f"Sending request to Dify endpoint: {dify_endpoint}, stream={stream}")

        if stream:
            def generate():
                client = get_http_client()
                
                def flush_chunk(chunk_data):
                    """Helper function to flush chunks immediately"""
                    return chunk_data.encode('utf-8')
                
                def calculate_delay(buffer_size):
                    """
                    æ ¹æ®ç¼“å†²åŒºå¤§å°åŠ¨æ€è®¡ç®—å»¶è¿Ÿ
                    buffer_size: ç¼“å†²åŒºä¸­å‰©ä½™çš„å­—ç¬¦æ•°é‡
                    """
                    if buffer_size > 30:  # ç¼“å†²åŒºå†…å®¹è¾ƒå¤šï¼Œå¿«é€Ÿè¾“å‡º
                        return 0.001  # 5mså»¶è¿Ÿ
                    elif buffer_size > 20:  # ä¸­ç­‰æ•°é‡ï¼Œé€‚ä¸­é€Ÿåº¦
                        return 0.002  # 10mså»¶è¿Ÿ
                    elif buffer_size > 10:  # è¾ƒå°‘å†…å®¹ï¼Œç¨æ…¢é€Ÿåº¦
                        return 0.01  # 20mså»¶è¿Ÿ
                    else:  # å†…å®¹å¾ˆå°‘ï¼Œä½¿ç”¨è¾ƒæ…¢çš„é€Ÿåº¦
                        return 0.02  # 30mså»¶è¿Ÿ
                
                def send_char(char, message_id):
                    """Helper function to send single character"""
                    openai_chunk = {
                        "id": message_id,
                        "object": "chat.completion.chunk",
                        "created": int(time.time()),
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "delta": {
                                "content": char
                            },
                            "finish_reason": None
                        }]
                    }
                    chunk_data = f"data: {json.dumps(openai_chunk)}\n\n"
                    return flush_chunk(chunk_data)
                
                # åˆå§‹åŒ–ç¼“å†²åŒº
                output_buffer = []
                
                try:
                    # ç§»é™¤é¢„è¿æ¥æ£€æŸ¥ï¼Œç›´æ¥è¿›è¡Œæµå¼è¯·æ±‚
                    # é¢„è¿æ¥æ£€æŸ¥å¯èƒ½è¿‡äºä¸¥æ ¼ï¼Œå½±å“æ­£å¸¸æµå¼å“åº”
                    
                    with client.stream(
                        'POST',
                        dify_endpoint,
                        json=dify_request,
                        headers={
                            **headers,
                            'Accept': 'text/event-stream',
                            'Cache-Control': 'no-cache',
                            'Connection': 'keep-alive'
                        }
                    ) as response:
                        generate.message_id = None
                        buffer = ""
                        
                        for raw_bytes in response.iter_raw():
                            if not raw_bytes:
                                continue
                                
                            try:
                                buffer += raw_bytes.decode('utf-8')
                                
                                while '\n' in buffer:
                                    line, buffer = buffer.split('\n', 1)
                                    line = line.strip()
                                    
                                    if not line or not line.startswith('data: '):
                                        continue
                                        
                                    try:
                                        json_str = line[6:]
                                        dify_chunk = json.loads(json_str)
                                        
                                        if dify_chunk.get("event") == "message" and "answer" in dify_chunk:
                                            current_answer = dify_chunk["answer"]
                                            if not current_answer:
                                                continue
                                                
                                            message_id = dify_chunk.get("message_id", "")
                                            if not generate.message_id:
                                                generate.message_id = message_id
                                                # åœ¨æµå¼å“åº”çš„ç¬¬ä¸€ä¸ªæ¶ˆæ¯ä¸­æ›´æ–°æ˜ å°„
                                                update_conversation_mapping(webui_chat_id, dify_chunk)
                                            
                                            # å°†å½“å‰æ‰¹æ¬¡çš„å­—ç¬¦æ·»åŠ åˆ°è¾“å‡ºç¼“å†²åŒº
                                            for char in current_answer:
                                                output_buffer.append((char, generate.message_id))
                                            
                                            # æ ¹æ®ç¼“å†²åŒºå¤§å°åŠ¨æ€è°ƒæ•´è¾“å‡ºé€Ÿåº¦
                                            while output_buffer:
                                                char, msg_id = output_buffer.pop(0)
                                                yield send_char(char, msg_id)
                                                # æ ¹æ®å‰©ä½™ç¼“å†²åŒºå¤§å°è®¡ç®—å»¶è¿Ÿ
                                                delay = calculate_delay(len(output_buffer))
                                                time.sleep(delay)
                                            
                                            # ç«‹å³ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè¯·æ±‚
                                            continue
                                        
                                        elif dify_chunk.get("event") == "message_end":
                                            # å¿«é€Ÿè¾“å‡ºå‰©ä½™å†…å®¹
                                            while output_buffer:
                                                char, msg_id = output_buffer.pop(0)
                                                yield send_char(char, msg_id)
                                                time.sleep(0.001)  # å›ºå®šä½¿ç”¨æœ€å°å»¶è¿Ÿå¿«é€Ÿè¾“å‡ºå‰©ä½™å†…å®¹
                                            
                                            final_chunk = {
                                                "id": generate.message_id,
                                                "object": "chat.completion.chunk",
                                                "created": int(time.time()),
                                                "model": model,
                                                "choices": [{
                                                    "index": 0,
                                                    "delta": {},
                                                    "finish_reason": "stop"
                                                }]
                                            }
                                            yield flush_chunk(f"data: {json.dumps(final_chunk)}\n\n")
                                            yield flush_chunk("data: [DONE]\n\n")
                                        
                                    except json.JSONDecodeError as e:
                                        logger.warning(f"JSON decode error in streaming response: {str(e)}, line: {json_str[:100]}...")
                                        continue
                                        
                            except Exception as e:
                                logger.error(f"Error processing chunk: {str(e)}")
                                continue

                except httpx.ConnectTimeout as e:
                    logger.error(f"Stream connection timeout: {e}")
                    yield flush_chunk(f"data: {{\"error\": \"Connection timeout: {str(e)}\"}}\n\n")
                    yield flush_chunk("data: [DONE]\n\n")
                except httpx.RequestError as e:
                    logger.error(f"Stream request error: {e}")
                    yield flush_chunk(f"data: {{\"error\": \"Request error: {str(e)}\"}}\n\n")
                    yield flush_chunk("data: [DONE]\n\n")
                except Exception as e:
                    logger.error(f"Unexpected stream error: {e}")
                    yield flush_chunk(f"data: {{\"error\": \"Internal error: {str(e)}\"}}\n\n")
                    yield flush_chunk("data: [DONE]\n\n")
                finally:
                    # ä½¿ç”¨å…¨å±€å®¢æˆ·ç«¯ï¼Œä¸éœ€è¦æ‰‹åŠ¨å…³é—­
                    pass

            return Response(
                stream_with_context(generate()),
                content_type='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache, no-transform',
                    'Connection': 'keep-alive',
                    'Transfer-Encoding': 'chunked',
                    'X-Accel-Buffering': 'no',
                    'Content-Encoding': 'none'
                },
                direct_passthrough=True
            )
        else:
            # ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯å¤„ç†éæµå¼å“åº”
            try:
                client = get_http_client()
                response = client.post(
                    dify_endpoint,
                    json=dify_request,
                    headers=headers
                )
                
                if response.status_code != 200:
                    error_msg = f"Dify API error: {response.text}"
                    logger.error(f"Request failed: {error_msg}")
                    return {
                        "error": {
                            "message": error_msg,
                            "type": "api_error",
                            "code": response.status_code
                        }
                    }, response.status_code

                dify_response = response.json()
                logger.info(f"Received response from Dify: {json.dumps(dify_response, ensure_ascii=False)}")
                
                # æ›´æ–°ä¼šè¯æ˜ å°„
                update_conversation_mapping(webui_chat_id, dify_response)
                
                openai_response = transform_dify_to_openai(dify_response, model=model)
                return openai_response
                
            except httpx.TimeoutException as e:
                error_msg = f"Request timeout: {str(e)}"
                logger.error(f"Timeout error for model {model}: {error_msg}")
                return {
                    "error": {
                        "message": error_msg,
                        "type": "timeout_error",
                        "code": "request_timeout"
                    }
                }, 408
            except httpx.ConnectError as e:
                error_msg = f"Failed to connect to Dify API: {str(e)}"
                logger.error(f"Connection error for model {model}: {error_msg}")
                return {
                    "error": {
                        "message": error_msg,
                        "type": "connection_error", 
                        "code": "connection_failed"
                    }
                }, 503
            except httpx.RequestError as e:
                error_msg = f"Request failed: {str(e)}"
                logger.error(f"Request error for model {model}: {error_msg}")
                return {
                    "error": {
                        "message": error_msg,
                        "type": "api_error",
                        "code": "request_failed"
                    }
                }, 503

    except Exception as e:
        logger.exception("Unexpected error occurred")
        return {
            "error": {
                "message": str(e),
                "type": "internal_error",
            }
        }, 500

@app.route('/v1/models', methods=['GET'])
def list_models():
    """è¿”å›å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    logger.info("Listing available models")
    # è¿‡æ»¤æ‰æ²¡æœ‰APIå¯†é’¥çš„æ¨¡å‹
    available_models = [
        model for model in AVAILABLE_MODELS 
        if MODEL_TO_API_KEY.get(model["id"])
    ]
    
    response = {
        "object": "list",
        "data": available_models
    }
    logger.info(f"Available models: {json.dumps(response, ensure_ascii=False)}")
    return response

@app.route('/v1/conversation/mappings', methods=['GET'])
def get_conversation_mappings():
    """è·å–å½“å‰çš„ä¼šè¯æ˜ å°„çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    stats = conversation_mapper.get_mapping_stats()
    return {
        "mapping_count": stats["total"],
        "oldest_mapping": stats["oldest"],
        "newest_mapping": stats["newest"],
        "timestamp": int(time.time())
    }

@app.route('/v1/conversation/cleanup', methods=['POST'])
def cleanup_old_conversations():
    """æ¸…ç†æ—§çš„ä¼šè¯æ˜ å°„"""
    max_age_days = request.json.get('max_age_days', 30) if request.is_json else 30
    removed_count = conversation_mapper.cleanup_old_mappings(max_age_days)
    return {
        "removed_count": removed_count,
        "max_age_days": max_age_days,
        "timestamp": int(time.time())
    }

if __name__ == '__main__':
    # éªŒè¯é…ç½®
    if not validate_startup_config():
        logger.error("âŒ Startup aborted due to configuration errors")
        exit(1)
    
    host = os.getenv("SERVER_HOST", "127.0.0.1")
    port = int(os.getenv("SERVER_PORT", 5000))
    logger.info(f"ğŸš€ Starting OpenDify server on http://{host}:{port}")
    
    try:
        app.run(debug=True, host=host, port=port)
    except KeyboardInterrupt:
        logger.info("Shutting down server...")
    finally:
        cleanup_http_client()
