#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šä» JSON æ–‡ä»¶è¿ç§»åˆ° SQLite æ•°æ®åº“
ç”¨äºä»æ—§ç‰ˆæœ¬çš„ ConversationMapper è¿ç§»åˆ°æ–°çš„ SQLite ç‰ˆæœ¬
"""

import json
import os
import sys
import logging
from conversation_mapper_sqlite import ConversationMapper

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def migrate_json_to_sqlite(json_file_path="data/conversation_mappings.json", 
                          sqlite_db_path="data/conversation_mappings.db"):
    """
    å°† JSON æ ¼å¼çš„ä¼šè¯æ˜ å°„è¿ç§»åˆ° SQLite æ•°æ®åº“
    
    Args:
        json_file_path: åŸ JSON æ–‡ä»¶è·¯å¾„
        sqlite_db_path: ç›®æ ‡ SQLite æ•°æ®åº“è·¯å¾„
    """
    
    # æ£€æŸ¥ JSON æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file_path):
        logger.info(f"ğŸ“‚ JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        logger.info("âœ… æ— éœ€è¿ç§»ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ SQLite ç‰ˆæœ¬")
        return True
    
    # æ£€æŸ¥ SQLite æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(sqlite_db_path):
        logger.warning(f"âš ï¸  SQLite æ•°æ®åº“å·²å­˜åœ¨: {sqlite_db_path}")
        response = input("æ˜¯å¦è¦è¦†ç›–ç°æœ‰æ•°æ®åº“ï¼Ÿ(y/N): ").strip().lower()
        if response != 'y':
            logger.info("âŒ è¿ç§»å·²å–æ¶ˆ")
            return False
        
        # å¤‡ä»½ç°æœ‰æ•°æ®åº“
        backup_path = sqlite_db_path + ".backup"
        os.rename(sqlite_db_path, backup_path)
        logger.info(f"ğŸ“‹ å·²å¤‡ä»½ç°æœ‰æ•°æ®åº“åˆ°: {backup_path}")
    
    try:
        # è¯»å– JSON æ•°æ®
        logger.info(f"ğŸ“– æ­£åœ¨è¯»å– JSON æ–‡ä»¶: {json_file_path}")
        with open(json_file_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(json_data)} æ¡æ˜ å°„è®°å½•")
        
        if not json_data:
            logger.info("âœ… JSON æ–‡ä»¶ä¸ºç©ºï¼Œæ— éœ€è¿ç§»")
            return True
        
        # åˆ›å»º SQLite æ•°æ®åº“
        logger.info(f"ğŸ—„ï¸  åˆ›å»º SQLite æ•°æ®åº“: {sqlite_db_path}")
        mapper = ConversationMapper(sqlite_db_path)
        
        # è¿ç§»æ•°æ®
        migrated_count = 0
        errors = 0
        
        for webui_chat_id, mapping_info in json_data.items():
            try:
                if isinstance(mapping_info, dict):
                    # æ–°æ ¼å¼ï¼ˆåŒ…å« created_at, last_used ç­‰ä¿¡æ¯ï¼‰
                    dify_conversation_id = mapping_info.get('dify_conversation_id')
                    if dify_conversation_id:
                        mapper.set_mapping(webui_chat_id, dify_conversation_id)
                        migrated_count += 1
                    else:
                        logger.warning(f"âš ï¸  è·³è¿‡ç¼ºå°‘ dify_conversation_id çš„è®°å½•: {webui_chat_id[:8]}...")
                        errors += 1
                elif isinstance(mapping_info, str):
                    # æ—§æ ¼å¼ï¼ˆç›´æ¥å­˜å‚¨ dify_conversation_idï¼‰
                    mapper.set_mapping(webui_chat_id, mapping_info)
                    migrated_count += 1
                else:
                    logger.warning(f"âš ï¸  è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„è®°å½•: {webui_chat_id[:8]}...")
                    errors += 1
                    
            except Exception as e:
                logger.error(f"âŒ è¿ç§»è®°å½•å¤±è´¥ {webui_chat_id[:8]}...: {e}")
                errors += 1
        
        # éªŒè¯è¿ç§»ç»“æœ
        final_stats = mapper.get_mapping_stats()
        
        logger.info("ğŸ“Š è¿ç§»ç»“æœ:")
        logger.info(f"   - æˆåŠŸè¿ç§»: {migrated_count} æ¡è®°å½•")
        logger.info(f"   - è¿ç§»é”™è¯¯: {errors} æ¡è®°å½•")
        logger.info(f"   - æ•°æ®åº“è®°å½•æ€»æ•°: {final_stats['total']}")
        
        if final_stats['total'] == migrated_count:
            logger.info("âœ… æ•°æ®è¿ç§»æˆåŠŸï¼")
            
            # å¤‡ä»½åŸ JSON æ–‡ä»¶
            json_backup_path = json_file_path + ".backup"
            os.rename(json_file_path, json_backup_path)
            logger.info(f"ğŸ“‹ å·²å¤‡ä»½åŸ JSON æ–‡ä»¶åˆ°: {json_backup_path}")
            
            # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
            db_info = mapper.get_database_info()
            logger.info(f"ğŸ—„ï¸  æ•°æ®åº“ä¿¡æ¯:")
            logger.info(f"   - è·¯å¾„: {db_info.get('database_path')}")
            logger.info(f"   - å¤§å°: {db_info.get('database_size_bytes', 0)} å­—èŠ‚")
            logger.info(f"   - æ¨¡å¼: {db_info.get('journal_mode', 'unknown')}")
            
            return True
        else:
            logger.error("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¿ç§»å¯èƒ½ä¸å®Œæ•´")
            return False
            
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSON æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ OpenDify æ•°æ®åº“è¿ç§»å·¥å…·")
    logger.info("ä» JSON æ–‡ä»¶è¿ç§»åˆ° SQLite æ•°æ®åº“")
    logger.info("-" * 50)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    json_path = "data/conversation_mappings.json"
    sqlite_path = "data/conversation_mappings.db"
    
    if len(sys.argv) > 1:
        json_path = sys.argv[1]
    if len(sys.argv) > 2:
        sqlite_path = sys.argv[2]
    
    logger.info(f"ğŸ“‚ JSON æ–‡ä»¶: {json_path}")
    logger.info(f"ğŸ—„ï¸  SQLite æ•°æ®åº“: {sqlite_path}")
    logger.info("-" * 50)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(sqlite_path), exist_ok=True)
    
    # æ‰§è¡Œè¿ç§»
    success = migrate_json_to_sqlite(json_path, sqlite_path)
    
    if success:
        logger.info("ğŸ‰ è¿ç§»å®Œæˆï¼")
        logger.info("ğŸ’¡ æç¤º:")
        logger.info("   - ç°åœ¨å¯ä»¥ä½¿ç”¨æ–°çš„ SQLite ConversationMapper")
        logger.info("   - æ”¯æŒå¤šè¿›ç¨‹å¹¶å‘å®‰å…¨")
        logger.info("   - æ›´å¥½çš„æ€§èƒ½å’Œå¯é æ€§")
        logger.info("   - å¯ä»¥åˆ é™¤å¤‡ä»½æ–‡ä»¶å¦‚æœç¡®è®¤æ— è¯¯")
        sys.exit(0)
    else:
        logger.error("âŒ è¿ç§»å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()